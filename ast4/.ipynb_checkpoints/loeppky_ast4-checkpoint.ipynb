{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38bac07b",
   "metadata": {},
   "source": [
    "# Assignment 4\n",
    "\n",
    "## EOSC 510\n",
    "\n",
    "## Andrew Loeppky"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5272c49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8f57ba",
   "metadata": {},
   "source": [
    "## Part 0 - Get the raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d993adf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data.csv\")\n",
    "\n",
    "data.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63af55e8",
   "metadata": {},
   "source": [
    "## Part 1 - Model design\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f083b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define RMSE as a function, since we'll use this in the NN model \n",
    "def rmse(target,prediction):\n",
    "    return(np.sqrt(((target - prediction)**2).sum()/len(target)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e8ee02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unpack data\n",
    "x1 = data[\"x1\"]\n",
    "x2 = data[\"x2\"]\n",
    "y = data[\"y\"]\n",
    "x1test = data[\"x1test\"]\n",
    "x2test = data[\"x2test\"]\n",
    "\n",
    "x_realtest = np.array([x1test[np.isnan(x1test) == False], x2test[np.isnan(x2test) == False]]).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4249624",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_realtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f332761f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale y on [0,1]\n",
    "y-=np.min(y)\n",
    "y/=np.max(y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7b0e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide into training and validation datasets\n",
    "ntrain = int(len(y) * 0.7)\n",
    "\n",
    "# training set\n",
    "x1_train = x1[:ntrain]\n",
    "x2_train = x2[:ntrain]\n",
    "x_train = np.array([x1_train, x2_train]).T\n",
    "\n",
    "y_train = y[:ntrain]\n",
    "\n",
    "# validation set\n",
    "x1_test = x1[ntrain:]\n",
    "x2_test = x2[ntrain:]\n",
    "x_test = np.array([x1_test, x2_test]).T\n",
    "y_test = y[ntrain:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9549ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Play around with these parameters\n",
    "num_models = 20 #number of models to build for the ensemble\n",
    "min_nhn = 1 #minimum number of hidden neurons to loop through (nhn = 'number hidden neurons')\n",
    "max_nhn = 9 #maximum number of hidden neurons to loop through\n",
    "max_hidden_layers = 2 #maximum number of hidden layers to loop through (nhl = 'number hidden layers')\n",
    "batch_size = 32\n",
    "solver = 'adam' #use stochastic gradient descent as an optimization method (weight updating algorithm)\n",
    "activation = 'relu'\n",
    "learning_rate_init = 0.01\n",
    "#####\n",
    "\n",
    "max_iter = 1500 #max number of epochs to run\n",
    "early_stopping = True #True = stop early if validation error begins to rise\n",
    "validation_fraction = 0.1 #fraction of training data to use as validation\n",
    "\n",
    "y_out_all_nhn = []\n",
    "y_out_ensemble = []\n",
    "RMSE_ensemble = [] #RMSE for each model in the ensemble\n",
    "RMSE_ensemble_cumsum = [] #RMSE of the cumulative saltation for each model\n",
    "nhn_best = []\n",
    "nhl_best = []\n",
    "##########################################################################\n",
    "y_out_ensemble_real = []\n",
    "##########################################################################\n",
    "\n",
    "for model_num in range(num_models): #for each model in the ensemble\n",
    "    \n",
    "    print('Model Number: ' + str(model_num))\n",
    "    \n",
    "    RMSE = []\n",
    "    y_out_all_nhn = []\n",
    "    nhn = []\n",
    "    nhl = []\n",
    "    \n",
    "    for num_hidden_layers in range(1,max_hidden_layers+1):\n",
    "    \n",
    "        print('\\t # Hidden Layers = ' + str(num_hidden_layers))\n",
    "    \n",
    "        for num_hidden_neurons in range(min_nhn,max_nhn+1): #for each number of hidden neurons\n",
    "\n",
    "            print('\\t\\t # hidden neurons = ' + str(num_hidden_neurons))\n",
    "            \n",
    "            hidden_layer_sizes = (num_hidden_neurons,num_hidden_layers)\n",
    "            model = MLPRegressor(hidden_layer_sizes=hidden_layer_sizes, \n",
    "                                 verbose=False,\n",
    "                                 max_iter=max_iter, \n",
    "                                 early_stopping = early_stopping,\n",
    "                                 validation_fraction = validation_fraction,\n",
    "                                 batch_size = batch_size,\n",
    "                                 solver = solver,\n",
    "                                 activation = activation,\n",
    "                                 learning_rate_init = learning_rate_init)\n",
    "\n",
    "            model.fit(x_train,y_train) #train the model\n",
    "\n",
    "            y_out_this_nhn = model.predict(x_test) #model prediction for this number of hidden neurons (nhn)\n",
    "            y_out_all_nhn.append(y_out_this_nhn) #store all models -- will select best one best on RMSE\n",
    "            \n",
    "            ###############################################################################################\n",
    "            y_out_real = model.predict(x_realtest) # predict the non-training set using current model\n",
    "            y_out_all_real.append(y_out_real)\n",
    "            ###############################################################################################\n",
    "\n",
    "            RMSE.append(rmse(y_test,y_out_this_nhn)) #RMSE between cumulative curves\n",
    "            \n",
    "            nhn.append(num_hidden_neurons)\n",
    "            nhl.append(num_hidden_layers)\n",
    "        \n",
    "    indBest = RMSE.index(np.min(RMSE)) #index of model with lowest RMSE\n",
    "    RMSE_ensemble.append(np.min(RMSE))\n",
    "    nhn_best.append(nhn[indBest])\n",
    "    nhl_best.append(nhl[indBest])\n",
    "    #nhn_best.append(indBest+1) #the number of hidden neurons that achieved best model performance of this model iteration\n",
    "    y_out_ensemble.append(y_out_all_nhn[indBest])\n",
    "    ###############################################\n",
    "    y_out_ensemble_real.append(y_out_real[indBest])\n",
    "    ###############################################\n",
    "    print('\\t BEST: ' + str(nhl_best[model_num]) + ' hidden layers, '+ str(nhn_best[model_num]) + ' hidden neurons')\n",
    "    \n",
    "y_out_ensemble_mean = np.mean(y_out_ensemble,axis=0)\n",
    "RMSE_ensemble_mean = rmse(y_out_ensemble_mean,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53079c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "\n",
    "plt.subplot(241)\n",
    "plt.scatter(len(RMSE_ensemble),RMSE_ensemble_mean,c='k',marker='*')\n",
    "plt.scatter(range(len(RMSE_ensemble)),RMSE_ensemble)\n",
    "plt.xlabel('Model #')\n",
    "plt.ylabel('RMSE')\n",
    "plt.title('Error')\n",
    "\n",
    "plt.subplot(242)\n",
    "plt.scatter(range(len(nhn_best)),nhn_best)\n",
    "plt.xlabel('Model #')\n",
    "plt.ylabel('# Hidden Neurons')\n",
    "plt.title('Hidden Neurons')\n",
    "\n",
    "plt.subplot(243)\n",
    "plt.scatter(range(len(nhl_best)),nhl_best)\n",
    "plt.xlabel('Model #')\n",
    "plt.ylabel('# Hidden Layers')\n",
    "plt.title('Hidden Layers')\n",
    "\n",
    "plt.subplot(244)\n",
    "plt.scatter(y_test,y_out_ensemble_mean)\n",
    "#plt.plot((np.min(y_test),np.max(y_test)),'k--')\n",
    "plt.xlabel('y_test')\n",
    "plt.ylabel('y_model')\n",
    "plt.title('Ensemble')\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.plot(y_out_ensemble_mean, label=\"Ensemble Mean\")\n",
    "plt.plot(np.array(y_test),alpha = 0.5, label=\"Ytest\")\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da621b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize individual model runs\n",
    "\n",
    "saveIt = 0\n",
    "\n",
    "plt.figure(figsize = (12,5))\n",
    "\n",
    "plt.scatter(range(len(y_test)),y_test,label='Observations',zorder = 0,alpha = 0.3)\n",
    "plt.plot(range(len(y_test)),np.transpose(y_out_ensemble[0]),color = 'k',alpha = 0.4,label='Individual Models',zorder=1) #plot first ensemble member with a label\n",
    "plt.plot(range(len(y_test)),np.transpose(y_out_ensemble[1:]),color = 'k',alpha = 0.4,zorder=1) #plot remaining ensemble members without labels for a nicer legend\n",
    "plt.plot(range(len(y_test)),y_out_ensemble_mean,color = 'k',label = 'Ensemble',zorder=2, linewidth = 3)\n",
    "plt.xlabel('Time', fontsize = 20)\n",
    "plt.ylabel('y', fontsize = 20)\n",
    "plt.xticks(fontsize = 16)\n",
    "plt.yticks(fontsize = 16)\n",
    "plt.title('MLP Model Results', fontsize = 24)\n",
    "plt.legend(fontsize = 16, loc = 'best')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "if saveIt:\n",
    "    plt.savefig('tutorial10_fig12.png')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f96a232",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize performance metrics/etc\n",
    "\n",
    "saveIt = 0\n",
    "\n",
    "plt.figure(figsize=(16,4))\n",
    "\n",
    "plt.subplot(131)\n",
    "plt.scatter(len(RMSE_ensemble),RMSE_ensemble_mean,c='k',marker='*', s = 150)\n",
    "plt.scatter(range(len(RMSE_ensemble)),RMSE_ensemble, s = 150)\n",
    "#plt.axhline(np.mean(RMSE_ensemble), color=\"r\", alpha=0.5, linestyle=\":\")\n",
    "plt.xlabel('Model #', fontsize = 20)\n",
    "plt.ylabel('RMSE', fontsize = 20)\n",
    "plt.xticks(fontsize = 16)\n",
    "plt.yticks(fontsize = 16)\n",
    "#plt.ylim((np.min(RMSE_ensemble) - 0.005, np.max(RMSE_ensemble)+0.005))\n",
    "plt.title('Error', fontsize = 20)\n",
    "\n",
    "plt.subplot(132)\n",
    "plt.scatter(range(len(nhn_best)),nhn_best, s = 150)\n",
    "plt.xlabel('Model #', fontsize = 20)\n",
    "plt.ylabel('# Hidden Neurons', fontsize = 20)\n",
    "plt.xticks(fontsize = 16)\n",
    "plt.yticks(fontsize = 16)\n",
    "plt.title('Hidden Neurons', fontsize = 20)\n",
    "\n",
    "plt.subplot(133)\n",
    "plt.scatter(range(len(nhl_best)),nhl_best, s = 150)\n",
    "plt.xlabel('Model #', fontsize = 20)\n",
    "plt.ylabel('# Hidden Layers', fontsize = 20)\n",
    "plt.xticks(fontsize = 16)\n",
    "plt.yticks(fontsize = 16)\n",
    "plt.title('Hidden Layers', fontsize = 20)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "if saveIt:\n",
    "    plt.savefig('tutorial10_fig10.png')\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5825689d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_out_ensemble_real"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
