{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d498c152",
   "metadata": {},
   "source": [
    "# Wildfire Smoke Controls on Gross Primary Production in Central Canada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e3b0496",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats.stats import pearsonr\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# get Sam's stepwise selection function\n",
    "import statsmodels.api as sm\n",
    "%run ../lab02/Tutorial_2_2021_functions2.ipynb\n",
    "\n",
    "# show full dataframes\n",
    "pd.set_option('max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ee9bc97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data\n",
    "data_in = pd.read_csv(\"drf_timeseries.csv\", parse_dates=True, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4b1ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_in[\"datetime\"] = pd.to_datetime(data_in[\"datetime\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ec693c",
   "metadata": {},
   "source": [
    "## Select only the relevant months\n",
    "\n",
    "This study is really only concerned with what goes on between May and September, as the vast majority of primary production (trees photosynthesizing/consuming CO2) and wildfire activity happen in the summer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a09d938",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select just the growing/wildfire season (may-sept, inclusive)\n",
    "growing_season = pd.DataFrame()\n",
    "#for month in [5,6,7,8,9]:\n",
    "for month in [1,2,3,4,5,6,7,8,9,10,11,12]:\n",
    "    growing_season = growing_season.append(data_in[pd.to_datetime(data_in['datetime']).dt.month == month])\n",
    "growing_season = growing_season.sort_values(by='datetime')\n",
    "#growing_season[\"year\"] = pd.to_datetime(data_in['datetime']).dt.year"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19bb7d23",
   "metadata": {},
   "source": [
    "## Find which measurements have the most complete data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f2ef07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check data for completeness\n",
    "def check_complete(data_in):\n",
    "    \"\"\"\n",
    "    Prints out the percentage of non-NaN values in a dataset\n",
    "    \"\"\"\n",
    "    data_len = np.shape(data_in)[0]\n",
    "    for key in data_in.keys():\n",
    "        if key != \"datetime\":\n",
    "            not_nans = np.shape((data_in[np.isnan(data_in[key]) == False]))[0]\n",
    "            completeness = not_nans / data_len * 100\n",
    "            print(f\"{key}:  {round(completeness,2)} %\")\n",
    "    return None\n",
    " \n",
    "\n",
    "def keep_complete(data_in, thres):\n",
    "    \"\"\"\n",
    "    returns a dataframe that contains a percentage of non-NaNs above\n",
    "    a specified threshhold\n",
    "    \"\"\"\n",
    "    data_out = pd.DataFrame()\n",
    "    data_out[\"datetime\"] = data_in[\"datetime\"]\n",
    "    data_len = np.shape(data_in)[0]\n",
    "    for key in data_in.keys():\n",
    "        if key != \"datetime\":\n",
    "            not_nans = np.shape((data_in[np.isnan(data_in[key]) == False]))[0]\n",
    "            completeness = not_nans / data_len * 100\n",
    "            if completeness >= thres:\n",
    "                data_out[key] = data_in[key]\n",
    "    return data_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3dda45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_complete(growing_season)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5191c045",
   "metadata": {},
   "source": [
    "Pretty dismal. We need the AOD data, so set a cutoff at 5%. We can hopefully interpolate the rest\n",
    "\n",
    "## Interpolation\n",
    "\n",
    "Now, go through each individual measurement and hand-tune the pandas interpolation scheme to come up with something realistic (If this can't be achieved, toss the whole column). There is a balance here, we are trying to maximize coverage where all columns are finite (not NaNs, so we can perform PCA on as big of dataset as possible), without dangerously extending data beyond what is physical.\n",
    "\n",
    "### AOD Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8f640d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = keep_complete(growing_season, 4.9)\n",
    "check_complete(data) # see if that worked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde5052f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all the AOD columns that survived the purge\n",
    "aod_list = []\n",
    "for key in data.keys():\n",
    "    if \"AOD\" in key:\n",
    "        aod_list.append(key)\n",
    "        print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0e069f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = keep_complete(growing_season, 4.9) # reset it\n",
    "# peek at the raw AOD data. How big of gaps am I willing to try to fill?\n",
    "fig, ax = plt.subplots(figsize=(15,4))\n",
    "data[aod_list][24000:30000].plot(alpha=0.5, ax=ax);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23964cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[aod_list] = data[aod_list].interpolate(method='time', limit=10, limit_direction='both')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15,4))\n",
    "data[aod_list][24000:30000].plot(alpha=0.5, ax=ax);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390c3a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# interpolation method I settled on (subject to change). Try messing around with this, \n",
    "# lots of methods available, most arent appropriate\n",
    "data[\"AOD_500nm\"].interpolate(method='slinear', limit=50, limit_direction='both').plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e597e3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now apply the interpolation scheme to all AOD sets\n",
    "for key in aod_list:\n",
    "    data[key] = data[key].interpolate(method='slinear', limit=500, limit_direction='both')\n",
    "data.plot('datetime', aod_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb5833d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Blanket interpolate all data using the same scheme (this is a bad idea)\n",
    "data_interp = data.interpolate(method='linear')#.dropna()\n",
    "data_interp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a99503",
   "metadata": {},
   "outputs": [],
   "source": [
    "# after we finish messing about with interpolations, drop all rows that still have missing data\n",
    "data_complete = data_interp.dropna()\n",
    "data_complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6768cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################\n",
    "# choose which version of the dataset to use here #\n",
    "###################################################\n",
    "\n",
    "#data = data_complete.drop(\"datetime\", axis=1)\n",
    "data = data_interp.drop(\"datetime\", axis=1).dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828b072b",
   "metadata": {},
   "source": [
    "## Part 2: Try PCA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a2dc4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = data_complete.drop(\"datetime\", axis=1)\n",
    "data = data_interp.drop(\"datetime\", axis=1).dropna()\n",
    "\n",
    "n_modes = np.min(np.shape(data))\n",
    "pca = PCA(n_components = n_modes)\n",
    "PCs = pca.fit_transform(data)\n",
    "eigvecs = pca.components_\n",
    "fracVar = pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccaddfd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot fraction of variance explained by each mode\n",
    "plt.figure(figsize=(10,5))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.scatter(range(len(fracVar)),fracVar)\n",
    "plt.xlabel('Mode Number')\n",
    "plt.ylabel('Fraction Variance Explained')\n",
    "plt.title('Variance Explained by All Modes')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "n_modes_show = 10\n",
    "plt.scatter(range(n_modes_show),fracVar[:n_modes_show])\n",
    "plt.xlabel('Mode Number')\n",
    "plt.ylabel('Fraction Variance Explained')\n",
    "plt.title('Variance Explained by First ' + str(n_modes_show) + ' Modes')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e97365d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(PCs[...,:4]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8c65eb",
   "metadata": {},
   "source": [
    "PCA works properly. What are the biggest contributors to the leading modes?\n",
    "\n",
    "## Multiple Linear Regression\n",
    "\n",
    "Perform MLR on the PCs to create a predictive model with inputs\n",
    "\n",
    "**PCs $\\rightarrow$ CO2 Fluxes**\n",
    "\n",
    "or, if we do rotated PCA:\n",
    "\n",
    "**smoke, PCs $\\rightarrow$ CO2 Fluxes**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d88caa6",
   "metadata": {},
   "source": [
    "## 1) MLR with the PCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19fca48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform MLR with the columns of the PCs\n",
    "### normalize the PCs first ###\n",
    "### only use a few PCs\n",
    "### separate carbon flux outputs ###\n",
    "\n",
    "\n",
    "# assign predictors and predictands\n",
    "X = pd.DataFrame(PCs)\n",
    "Y = data[\"FC\"]\n",
    "\n",
    "# Do MLR\n",
    "model = LinearRegression().fit(X, Y)\n",
    "ypred_MLR = model.predict(X)  # y predicted by MLR\n",
    "#intercept_MLR = model.intercept_[0]  # intercept predicted by MLR\n",
    "coef_MLR = model.coef_.flatten()  # regression coefficients in MLR model\n",
    "R2_MLR = model.score(X, Y)  # R-squared value from MLR model\n",
    "\n",
    "# Display the results\n",
    "for i, coef in enumerate(coef_MLR):\n",
    "    print(f\"PC{i}: {coef}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7595ff56",
   "metadata": {},
   "source": [
    "## 2) MLR With the Regular Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934b00c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign predictors and predictands\n",
    "X = data.drop(\"FC\", axis=1)\n",
    "Y = data[\"FC\"]\n",
    "\n",
    "# Do MLR\n",
    "model = LinearRegression().fit(X, Y)\n",
    "ypred_MLR = model.predict(X)  # y predicted by MLR\n",
    "#intercept_MLR = model.intercept_[0]  # intercept predicted by MLR\n",
    "coef_MLR = model.coef_.flatten()  # regression coefficients in MLR model\n",
    "R2_MLR = model.score(X, Y)  # R-squared value from MLR model\n",
    "\n",
    "# Display the results\n",
    "for col, coef in zip(data.keys(), coef_MLR):\n",
    "    print(f\"{col}: {coef}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2261fda",
   "metadata": {},
   "source": [
    "## To Do\n",
    "\n",
    "- Interpolate all columns, eyeball-optimizing between coverage and faithful interpolated values\n",
    "- chop out dates and outputs, perform PCA on everything else\n",
    "- try step 2 again, this time grouping on smoke level. Are the leading modes different?\n",
    "\n",
    "\n",
    "- Try it again with rotated PCA\n",
    "- Write up the presentation\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
